{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZYS7OWcn_w4",
        "outputId": "e84fdb61-735b-40be-d0dd-08d9a7566ff2"
      },
      "outputs": [],
      "source": [
        "! pip install optuna\n",
        "! pip install catboost\n",
        "! pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R71MRFteoEB-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    precision_recall_curve,\n",
        "    mean_squared_error\n",
        ")\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier, Pool, cv\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from pytorch_tabnet.metrics import Metric\n",
        "\n",
        "# 경고 메시지 무시\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# seed 설정\n",
        "seed = 400\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# GPU 사용이 가능하면 GPU 랜덤 시드도 설정\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R7q7Cz8oF2F",
        "outputId": "91e68cd7-7cbf-4c84-99c6-5e6c8f0068e3"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dHzUcR_ot-8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\") # 학습용 데이터\n",
        "df_test = pd.read_csv(\"submission.csv\") # 테스트 데이터(제출파일의 데이터)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLYbW_xETXVe"
      },
      "source": [
        "## data_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMLVF7aCSTOj",
        "outputId": "4e35a149-06ac-4492-acad-c273ba62d24f"
      },
      "outputs": [],
      "source": [
        "# 중복 데이터 제거\n",
        "df_train = df_train.drop_duplicates()\n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "7LFq7Mq7rRYr",
        "outputId": "49f327e1-1e5a-4214-b238-df5f3cfedbe5"
      },
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4MAgT0-SWSQ"
      },
      "outputs": [],
      "source": [
        "# 중복 제거한 이후 데이터 인덱스\n",
        "idx = [12764, 14640, 15041, 15229, 17580, 17582, 17884, 18943, 19077,\n",
        "       19355, 34058, 34249, 34250, 36195, 36213, 36228, 39329, 40206,\n",
        "       40826, 43245, 53956, 55462]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00PhUVCcSXgM",
        "outputId": "c3b008a0-d634-4304-b42c-76c8903662a7"
      },
      "outputs": [],
      "source": [
        "# 이상치라 판단된 행 제거\n",
        "df_train = df_train[~df_train.index.isin(idx)]\n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiAeMSOtSZm8"
      },
      "outputs": [],
      "source": [
        "def make_country_list(df1, df2):\n",
        "    df_all = pd.concat([df1, df2.drop('id', axis = 1)])\n",
        "\n",
        "    # null값은 모두 'unknown'으로 전처리\n",
        "    # 추후에 다시 0으로 처리\n",
        "    df_all['customer_country'] = df_all['customer_country'].fillna('unknown')\n",
        "    df_all['customer_country'] = df_all['customer_country'].str.lower()\n",
        "    # '/' 기준 분리 후 맨 뒤를 국적으로 별도 변수 생성\n",
        "    def country_split(text):\n",
        "        text = text.split('/')\n",
        "        return text[-1]\n",
        "    country_list = df_all['customer_country'].apply(country_split)\n",
        "    # 공백 제거\n",
        "    country_list = country_list.str.strip()\n",
        "\n",
        "    # 20개 이상 국가만 사용: 550 -> 83\n",
        "    country_list = list(country_list.value_counts()[:83].index)\n",
        "    country_list.remove('')\n",
        "    # indianapolis 는 US 도시\n",
        "    country_list.remove('india')\n",
        "    country_list.append('india')\n",
        "    return country_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgq5e4N3Sbst"
      },
      "outputs": [],
      "source": [
        "country_list = make_country_list(df_train, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH8QKdNpSjSJ"
      },
      "outputs": [],
      "source": [
        "def make_weight_dic(df):\n",
        "    df['expected_timeline'] = df['expected_timeline'].fillna('unknown')\n",
        "\n",
        "    delete_data = ['less than 3 months','3 months ~ 6 months','more than a year','9 months ~ 1 year',\n",
        "               '6 months ~ 9 months','less than 6 months']\n",
        "\n",
        "    # 명사와 동사만 남기는 전처리\n",
        "    def text_clean(text):\n",
        "        tokens = word_tokenize(text)\n",
        "        # 불용어 제거\n",
        "        stop_word = set(stopwords.words('english'))\n",
        "        tokens = [t for t in tokens if t not in stop_word]\n",
        "        pos_tags = pos_tag(tokens)\n",
        "\n",
        "        nouns = [word for word, pos in pos_tags if pos.startswith('N')]\n",
        "        verbs = [word for word, pos in pos_tags if pos.startswith('V')]\n",
        "\n",
        "        all = nouns + verbs\n",
        "\n",
        "        return all\n",
        "\n",
        "\n",
        "    # 실패/성공에 대한 결과가 있어야 하므로 train만 적용\n",
        "    # 영업전환 실패한 고객들의 timeline\n",
        "    timeline_f = []\n",
        "    for i in df[df['is_converted'] == False]['expected_timeline']:\n",
        "        if i not in delete_data:\n",
        "            text = text_clean(i)\n",
        "            timeline_f.extend(text)\n",
        "\n",
        "    # 영업전환 성공한 고객들의 timeline\n",
        "    timeline_t = []\n",
        "    for i in df[df['is_converted']]['expected_timeline']:\n",
        "        if i not in delete_data:\n",
        "            text = text_clean(i)\n",
        "            timeline_t.extend(text)\n",
        "\n",
        "    count_f = Counter(timeline_f).most_common()\n",
        "    count_f = pd.DataFrame(count_f, columns = ['word', 'count'])\n",
        "\n",
        "    count_t = Counter(timeline_t).most_common()\n",
        "    count_t = pd.DataFrame(count_t, columns = ['word', 'count'])\n",
        "\n",
        "    # 가장 빈도수 높은 단어 10개(실패)\n",
        "    dic_ex_f = count_f.head(10).set_index('word').to_dict()['count']\n",
        "\n",
        "    # 가장 빈도수 높은 단어 10개(성공)\n",
        "    # unknown 제외\n",
        "    dic_ex = count_t.head(10).set_index('word').to_dict()['count']\n",
        "\n",
        "    # top10 단어들로 가중치 주기\n",
        "    dic_ex_f['client'] = -10\n",
        "    dic_ex_f['details'] = -9\n",
        "    dic_ex_f['etc'] = -8\n",
        "    dic_ex_f['followed'] = -7\n",
        "    dic_ex_f['requirement'] = -6\n",
        "    dic_ex_f['shared'] = -5\n",
        "    dic_ex_f['system'] = -4\n",
        "    dic_ex_f['customer'] = -3\n",
        "    dic_ex_f['hence'] = -2\n",
        "    dic_ex_f['call'] = -1\n",
        "\n",
        "    dic_ex['demo'] = 10\n",
        "    dic_ex['client'] = 9\n",
        "    dic_ex['customer'] = 8\n",
        "    dic_ex['shared'] = 7\n",
        "    dic_ex['details'] = 6\n",
        "    dic_ex['call'] = 5\n",
        "    dic_ex['send'] = 4\n",
        "    dic_ex['discussed'] = 3\n",
        "    dic_ex['quote'] = 2\n",
        "    dic_ex['followed'] = 1\n",
        "\n",
        "    dic_all = {}\n",
        "\n",
        "    for key, value in dic_ex_f.items():\n",
        "        dic_all[key] = value\n",
        "\n",
        "    for key, value in dic_ex.items():\n",
        "        dic_all[key] = dic_all.get(key, 0) + value\n",
        "\n",
        "    return dic_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-NDtDZaSlY8"
      },
      "outputs": [],
      "source": [
        "dic_all = make_weight_dic(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3VgXnZGSmqc"
      },
      "outputs": [],
      "source": [
        "def preprocessing(df):\n",
        "    # product_category\n",
        "    product_dict = {}\n",
        "    product_dict['HVAC/ESS'] = ['control', 'ventilation', 'vrf', 'multi-split', 'single-split', 'chiller', 'heating']\n",
        "    product_dict['commercial display'] = ['oled signage', 'led signage', 'video wall signage', 'interactive signage',\n",
        "                                        'high brightness signage', 'special signage', 'standard signage', 'hotel tv', 'hospital tv', 'software solution',\n",
        "                                        'signage care solution', 'webos', 'procentric', 'one quick', 'interactive digital board']\n",
        "    product_dict['it products'] = ['monitor', 'laptop', 'projector', 'cloud device', 'medical display']\n",
        "\n",
        "    def original_category(text):\n",
        "        for key in product_dict.keys():\n",
        "            if text in product_dict[key]:\n",
        "                return key\n",
        "\n",
        "    # site 속 카테고리 기준 original 카테고리 변수 생성\n",
        "    df['category'] = df['product_category'].apply(original_category)\n",
        "\n",
        "    # ',' 포함한 데이터는 integrated solution으로 solution 카테고리로 처리\n",
        "    df.loc[df['product_category'].str.contains(',', na = False), 'category'] = 'solution'\n",
        "\n",
        "    # 임시로 nan으로 처리\n",
        "    df['category'] = df['category'].fillna('nan')\n",
        "\n",
        "    # product_dict로 처리되지 않은 카테고리 확인\n",
        "    df[df['category'] == 'nan']['product_category'].value_counts()\n",
        "\n",
        "    # 카테고리 입력 함수\n",
        "    def category_input(text, input):\n",
        "        df.loc[(df['product_category'].str.contains(text, na = False))&(df['category'] == 'nan'), 'category'] = input\n",
        "\n",
        "    # 언어 번역\n",
        "    def category_lang(text, input):\n",
        "        df.loc[df['product_category'].str.contains(text, na = False), 'product_category'] = input\n",
        "\n",
        "    # teto ou cassete inverter 번역 => 'ceiling or inverter cassette' => hvac/ess\n",
        "    category_lang('teto ou cassete inverter', 'ceiling or inverter cassette')\n",
        "\n",
        "    # rac => residential air conditioner => hvac/ess\n",
        "    category_lang('rac', 'residential air conditioner')\n",
        "\n",
        "    # ar condicionado residencial => residential air conditioner => hvac/ess\n",
        "    category_lang('ar condicionado residencial', 'residential air conditioning')\n",
        "\n",
        "    # outros => others\n",
        "    category_lang('outros', 'others')\n",
        "\n",
        "    # technical support, lg customer care program => support\n",
        "    category_input('technical support', 'support')\n",
        "    category_input('lg customer care program', 'support')\n",
        "\n",
        "    # scroll compressor => compressor/motor\n",
        "    category_input('scroll compressor', 'compressor/motor')\n",
        "\n",
        "    # robots => robot\n",
        "    category_input('robots', 'robot')\n",
        "\n",
        "\n",
        "    # ogrzewanie (pompy ciepła) => heating(heat pumps)\n",
        "    category_lang('ogrzewanie', 'heating(heat pumps)')\n",
        "\n",
        "    # aire acondicionado residencial => residential air conditioning\n",
        "    category_lang('aire acondicionado residencial', 'residential air conditioning')\n",
        "    # led 顯示屏 => led display\n",
        "    category_lang('led 顯示屏', 'led display')\n",
        "    # isıtma => heating\n",
        "    category_lang('isıtma', 'heating')\n",
        "    # lainnya => other\n",
        "    category_lang('lainnya', 'other')\n",
        "    # calefacción => heating\n",
        "    category_lang('calefacción', 'heating')\n",
        "    # 互動式顯示屏 => interactive display\n",
        "    category_lang('互動式顯示屏', 'interactive display')\n",
        "    # 標準顯示屏 => standard display\n",
        "    category_lang('標準顯示屏', 'standard display')\n",
        "    # điều hòa trung tâm vrf => vrf central air conditioner\n",
        "    category_lang('điều hòa trung tâm vrf', 'vrf central air conditioner')\n",
        "    # soğutucu => cooler\n",
        "    category_lang('soğutucu', 'cooler')\n",
        "    # تكييف وتبريد => conditioning and cooling\n",
        "    category_lang('تكييف وتبريد', 'conditioning and cooling')\n",
        "    # 特別顯示屏 => special display\n",
        "    category_lang('特別顯示屏', 'special display')\n",
        "    # מזגנים למקום מגורים => residential air conditioner\n",
        "    category_lang('מזגנים למקום מגורים', 'residential air conditioner')\n",
        "    # เครื่องปรับอากาศเผื่อที่อยู่อาศัย => residential air conditioner\n",
        "    category_lang('เครื่องปรับอากาศเผื่อที่อยู่อาศัย', 'residential air conditioner')\n",
        "    # חימום => heating\n",
        "    category_lang('חימום', 'heating')\n",
        "    # تكييفات => air conditioner\n",
        "    category_lang('تكييفات', 'air conditioner')\n",
        "    # điều hòa cục bộ => local air conditioning\n",
        "    category_lang('điều hòa cục bộ', 'local air conditioning')\n",
        "    # 醫院電視 => hospital tv\n",
        "    category_lang('醫院電視', 'hospital tv')\n",
        "    # 高亮度顯示屏 => high brightness display\n",
        "    category_lang('高亮度顯示屏', 'high brightness display')\n",
        "    # 軟體 => software\n",
        "    category_lang('軟體', 'software')\n",
        "    # פיצול מרובה => multi split\n",
        "    category_lang('פיצול מרובה', 'multi split')\n",
        "    # 酒店電視 => hotel tv\n",
        "    category_lang('酒店電視', 'hotel tv')\n",
        "    # حلول التدفئة => heating solution\n",
        "    category_lang('حلول التدفئة', 'heating solution')\n",
        "    # אחר => other\n",
        "    category_lang('אחר', 'other')\n",
        "    # مبرد (تشيلر) => chiller\n",
        "    category_lang('مبرد', 'chiller')\n",
        "    # ฯลฯ => etc.\n",
        "    category_lang('ฯลฯ', 'etc.')\n",
        "    # điều hòa gia dụng => household air conditioner\n",
        "    category_lang('điều hòa gia dụng', 'household air conditioner')\n",
        "    # khác => other\n",
        "    category_lang('khác', 'other')\n",
        "    # otros => others\n",
        "    category_lang('otros', 'others')\n",
        "    # pendingin => cooler\n",
        "    category_lang('pendingin', 'cooler')\n",
        "    # ac rumah => home air conditioning\n",
        "    category_lang('ac rumah', 'home air conditioning')\n",
        "    # climatiseur résidentiel => residential air conditioner\n",
        "    category_lang('climatiseur résidentiel', 'residential air conditioner')\n",
        "\n",
        "    # it ptoducts\n",
        "    it_products = ['pc', 'medical display', '28mq780', 'medical', 'monitor',\n",
        "                'radiology displays', 'bu50nst', 'notebook']\n",
        "    it_text = '|'.join(it_products)\n",
        "    category_input(it_text, 'it products')\n",
        "\n",
        "    # hvac/ess\n",
        "    hvac_products = ['all lg vrf systems', 'multi', 'a thermodynamic water heater',\n",
        "                    'residential', 'heating', 'chiller', 'condition', 'vrf',\n",
        "                    'cooler', 'split','energy storage system', 'cac', 'single cac',\n",
        "                    'system ac', 'ceiling or inverter cassette', 'residential air conditioner',\n",
        "                    'multi inverter', 'residential air conditioning', 'ess', 'drv']\n",
        "    hvac_text = '|'.join(hvac_products)\n",
        "    category_input(hvac_text, 'hvac/ess')\n",
        "\n",
        "    # commercial display\n",
        "    display_products = ['ur640', 'signage', 'virtual production', 'commercial tv',\n",
        "                        'videowall','43us660h0sd.awz','ledallinone','onequick',\n",
        "                        'led display','education createboard', '.awz','allinone',\n",
        "                        'leadallin','tv','fhd series', 'bwz', 'interactive display',\n",
        "                        'one quick', 'series', 'aio', 'led','lsca039','43us660h',\n",
        "                        '55vm5e', 'pro centric', 'gscd100','standard', 'lg magnit',\n",
        "                        '86uh5f', '49vl5f','98uh5e', '55vm5j-h', '55tc3d', '49vl5g-m', '55svh7f-a', 'hospitality', 'laec15',\n",
        "                        'retaildigital','gscd046', 'gsca046', 'collaboration displays', 'tr3', 'taa lcd lfd displays',\n",
        "                        'window facing display', 'special display', 'hoteleria_us670h', 'software',\n",
        "                        'laec015', 'high brightness display','videwall', 'idb', 'one:quick',\n",
        "                        'high brightness', 'video wall', 'pro:centric', 'commercial display',\n",
        "                        'lg paradise air solution'\n",
        "\n",
        "                        ]\n",
        "    display_text = '|'.join(display_products)\n",
        "    category_input(display_text, 'commercial display')\n",
        "\n",
        "    # product_dict로 처리되지 않은 카테고리 확인\n",
        "    df[df['category'] == 'nan']['product_category'].value_counts()\n",
        "\n",
        "    # 카테고리 입력 함수\n",
        "    # subcategory 기준\n",
        "    def sub_input(text, input):\n",
        "        df.loc[(df['product_subcategory'].str.contains(text, na = False))&(df['category'] == 'nan'), 'category'] = input\n",
        "\n",
        "    # product_subcategory, modelname만 적혀있는것도 큰 카테고리로 분류\n",
        "    df['product_subcategory'] = df['product_subcategory'].str.lower()\n",
        "\n",
        "    # จอภาพสำหรับการตรวจสอบทางคลินิก => monitor for clinical monitoring -> it products\n",
        "    # จอภาพเพื่อการวินิจฉัย => diagnostic monitor\n",
        "    # 其他 => other\n",
        "    df.loc[df['product_subcategory'].str.contains('其他', na = False), 'category'] = 'other'\n",
        "    # monitor => it products\n",
        "    it_sub = ['monitor', 'medical', 'จอภาพสำหรับการตรวจสอบทางคลินิก', 'จอภาพเพื่อการวินิจฉัย',\n",
        "            'cloud device', 'digital x-ray detectors', 'thin clients',\n",
        "            'all projectors', 'laptops', 'probeam', 'zero clients']\n",
        "    it_text = '|'.join(it_sub)\n",
        "    sub_input(it_text, 'it products')\n",
        "\n",
        "    # hvac/ess\n",
        "    hvac_sub = ['all lg vrf systems', 'multi', 'a thermodynamic water heater',\n",
        "                    'residential', 'heating', 'chiller', 'condition', 'vrf',\n",
        "                    'cooler', 'split','energy storage system', 'cac', 'single cac',\n",
        "                    'system ac', 'ess', '3.0 tr -1 nos. cassette']\n",
        "    hvac_text = '|'.join(hvac_sub)\n",
        "    sub_input(hvac_text, 'hvac/ess')\n",
        "\n",
        "    # commercial display\n",
        "    display_sub = ['pro:centric', 'signage', 'one:quick' ,'one-quick', 'webos box',\n",
        "                'interactive digital board', 'tr3dj series', 'tr3bg series',\n",
        "                'lg ops player', '65tr3bf', 'idb', 'lg smart cam pro','65tr3dj', 'supersign cms']\n",
        "    display_text = '|'.join(display_sub)\n",
        "    sub_input(display_text, 'commercial display')\n",
        "\n",
        "    # 처리되지 않은 subcategory 확인\n",
        "    df[df['category'] == 'nan']['product_subcategory'].value_counts()\n",
        "\n",
        "    # 카테고리 입력 함수\n",
        "    # modelname 기준\n",
        "    def model_input(text, input):\n",
        "        df.loc[(df['product_modelname'].str.contains(text, na = False))&(df['category'] == 'nan'), 'category'] = input\n",
        "\n",
        "    # modelname 카테고리 분류\n",
        "\n",
        "    it_model = ['UltraFine', '28MQ780', 'Ergo Dual', '21HQ513D', 'UltraWide', '32UN880',\n",
        "                '31HN713D', '14HQ701G-BP', '38CL950P', 'Radiology']\n",
        "    it_text = '|'.join(it_model)\n",
        "    model_input(it_text, 'it products')\n",
        "\n",
        "    # hvac/ess\n",
        "    hvac_model = ['all lg vrf systems', 'multi', 'a thermodynamic water heater',\n",
        "                    'residential', 'heating', 'chiller', 'condition', 'vrf',\n",
        "                    'cooler', 'split','energy storage system', 'cac', 'single cac',\n",
        "                    'system ac']\n",
        "    hvac_text = '|'.join(hvac_model)\n",
        "    model_input(hvac_text, 'hvac/ess')\n",
        "\n",
        "    # commercial display\n",
        "    display_model = ['43HT3WJ', '55CT5WJ', 'SC-00DA', 'LG SuperSign CMS', '65EP5G OLED Pro',\n",
        "                    '34WN780', 'IDB', 'LSVP']\n",
        "    display_text = '|'.join(display_model)\n",
        "    model_input(display_text, 'commercial display')\n",
        "\n",
        "    # 처리되지 않은 subcategory 확인\n",
        "    df[df['category'] == 'nan']['product_modelname'].value_counts()\n",
        "\n",
        "    # 처리되지 않은 것 모두 other로 통일\n",
        "    df[df['category'] == 'nan']['product_category'].value_counts()\n",
        "\n",
        "    df.loc[df['category'] == 'nan', 'category'] = 'other'\n",
        "\n",
        "    # product 변수 얼마나 작성하였는지\n",
        "    df['product_category'] = df['product_category'].fillna('unknown')\n",
        "    df['product_subcategory'] = df['product_subcategory'].fillna('unknown')\n",
        "    df['product_modelname'] = df['product_modelname'].fillna('unknown')\n",
        "\n",
        "    df['product_count'] = 0\n",
        "    for i, row in df.iterrows():\n",
        "        count = 0\n",
        "        if row['product_category'] != 'unknown':\n",
        "            count += 1\n",
        "        if row['product_subcategory'] != 'unknown':\n",
        "            count += 1\n",
        "        if row['product_modelname'] != 'unknown':\n",
        "            count += 1\n",
        "        df.loc[i, 'product_count'] = count\n",
        "\n",
        "    # '_' -> 공백으로 처리\n",
        "    df['expected_timeline'] = df['expected_timeline'].str.replace('_', ' ')\n",
        "\n",
        "    # null값 unknown\n",
        "    df['expected_timeline'] = df['expected_timeline'].fillna('unknown')\n",
        "\n",
        "    # 단어가 들어있는 비중에 따라 가중치\n",
        "    df['timeline_count'] = ''\n",
        "    for i, row in df.iterrows():\n",
        "        score = 0\n",
        "        if row['expected_timeline'] == 'unknown':\n",
        "            pass\n",
        "        else:\n",
        "            for key in dic_all.keys():\n",
        "                if key in row['expected_timeline']:\n",
        "                    score += dic_all[key]\n",
        "\n",
        "        df.loc[i, 'timeline_count'] = score\n",
        "\n",
        "    delete_data = ['less than 3 months','3 months ~ 6 months','more than a year','9 months ~ 1 year',\n",
        "                   '6 months ~ 9 months','less than 6 months']\n",
        "\n",
        "    df.loc[~df['expected_timeline'].isin(delete_data), 'expected_timeline'] = 0\n",
        "\n",
        "    df['historical_existing_cnt'] = df['historical_existing_cnt'].fillna(0)\n",
        "\n",
        "    # other 통일\n",
        "    df.loc[df['customer_job'].str.contains('other', na = False), 'customer_job'] = 'others'\n",
        "\n",
        "    # '_' 공백으로 변경\n",
        "    df['customer_job'] = df['customer_job'].str.replace('_', ' ')\n",
        "\n",
        "    # null값 0으로 처리\n",
        "    df['customer_job'] = df['customer_job'].fillna('others')\n",
        "\n",
        "\n",
        "    def job_categorize(text):\n",
        "        if 'accounting' in text:\n",
        "            return 'accounting'\n",
        "        elif 'administrative' in text:\n",
        "            return 'administrative'\n",
        "        elif 'arts and design' in text:\n",
        "            return 'arts and design'\n",
        "        elif 'business development' in text:\n",
        "            return 'business development'\n",
        "        elif 'community and social services' in text:\n",
        "            return 'community and social services'\n",
        "        elif 'consulting' in text:\n",
        "            return 'consulting'\n",
        "        elif 'curation' in text:\n",
        "            return 'curation'\n",
        "        elif 'education' in text:\n",
        "            return 'education'\n",
        "        elif 'engineering' in text:\n",
        "            return 'engineering'\n",
        "        elif 'entrepreneurship' in text:\n",
        "            return 'entrepreneurship'\n",
        "        elif 'finance' in text:\n",
        "            return 'finance'\n",
        "        elif 'healthcare services' in text:\n",
        "            return 'healthcare services'\n",
        "        elif 'human resources' in text:\n",
        "            return 'human resources'\n",
        "        elif 'information technology' in text:\n",
        "            return 'information technology'\n",
        "        elif 'legal' in text:\n",
        "            return 'legal'\n",
        "        elif 'marketing' in text:\n",
        "            return 'marketing'\n",
        "        elif 'media and communication' in text:\n",
        "            return 'media and communication'\n",
        "        elif 'military and protective services' in text:\n",
        "            return 'military and protective services'\n",
        "        elif 'operations' in text:\n",
        "            return 'operations'\n",
        "        elif 'product management' in text:\n",
        "            return 'product management'\n",
        "        elif 'program and project management' in text:\n",
        "            return 'program and project management'\n",
        "        elif 'purchasing' in text:\n",
        "            return 'purchasing'\n",
        "        elif 'quality assurance' in text:\n",
        "            return 'quality assurance'\n",
        "        elif 'real estate' in text:\n",
        "            return 'real estate'\n",
        "        elif 'research' in text:\n",
        "            return 'research'\n",
        "        elif 'sales' in text:\n",
        "            return 'sales'\n",
        "        elif 'support' in text:\n",
        "            return 'support'\n",
        "        else:\n",
        "            return 'other'\n",
        "\n",
        "    df['customer_job'] = df['customer_job'].apply(job_categorize)\n",
        "\n",
        "    # '-' 제거 및 '/' -> ','으로 처리\n",
        "    df['customer_type'] = df['customer_type'].str.replace('-', ' ')\n",
        "    df['customer_type'] = df['customer_type'].str.replace('/', ',')\n",
        "\n",
        "    # ',' 뒤에만 공백이 남도록 전처리\n",
        "    df['customer_type'] = df['customer_type'].apply(lambda x: re.sub(r'\\s*,\\s*', ', ', x) if isinstance(x, str) else x)\n",
        "\n",
        "    # other 통일\n",
        "    df.loc[df['customer_type'].str.contains('Other', na = False), 'customer_type'] = 'other'\n",
        "\n",
        "    # etc도 other로 통일\n",
        "    df['customer_type'] = df['customer_type'].str.replace('Etc.', 'other')\n",
        "\n",
        "    # homeowner 통일\n",
        "    df.loc[df['customer_type'].str.contains('Home', na = False), 'customer_type'] = 'Homeowner'\n",
        "\n",
        "    # 1. null값 모두 other로 변경해서 처리\n",
        "    df['customer_type'] = df['customer_type'].fillna('other')\n",
        "\n",
        "    # other를 0으로 전처리\n",
        "    df['customer_type'] = df['customer_type'].replace('other', 0)\n",
        "\n",
        "    # installer -> installer, contractor\n",
        "    df.loc[df['customer_type'].str.contains('Installer', na = False), 'customer_type'] = 'Installer, Contractor'\n",
        "\n",
        "    # distributor -> dealer, distributor\n",
        "    df.loc[df['customer_type'].str.contains('Distributor', na = False), 'customer_type'] = 'Dealer, Distributor'\n",
        "\n",
        "    # consultant -> architect, consultant\n",
        "    df.loc[df['customer_type'].str.contains('Consultant', na = False), 'customer_type'] = 'Architect, Consultant'\n",
        "\n",
        "    # 위에 false만 있는 값을 모두 모아 1로 묶음\n",
        "    df['customer_type'] = df['customer_type'].replace(['Corporate', 'Dealer, Distributor', 'System Integrator', 'Technician', 'Engineer', 'Manager, Director', 'Developer', 'End user', 'HVAC Engineer', 'Reseller', 'Software, Solution Provider', 'Technical Assistant', 'Commercial end user', 'Interior Designer', 'Administrator'], 1)\n",
        "\n",
        "    # 이건 모두 null값 0으로 처리\n",
        "    columns = ['id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver']\n",
        "\n",
        "    for col in columns:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "    # idit_all : id = 1, it =2, 결측치 = 0\n",
        "\n",
        "    # 'idit_all' 열 초기화\n",
        "    df['idit_all'] = 0\n",
        "\n",
        "    # 'id_strategic_ver'에서 1 -> 1\n",
        "    df.loc[df['id_strategic_ver'] == 1, 'idit_all'] = 1\n",
        "\n",
        "    # 'it_strategic_ver'에서 1 -> 2\n",
        "    df.loc[df['it_strategic_ver'] == 1, 'idit_all'] = 2\n",
        "\n",
        "    # 나머지는 0으로 저장\n",
        "    df['idit_all'].fillna(0)\n",
        "\n",
        "    # id_strategic_ver, it_strategic_ver, idit_strategic_ver 드롭\n",
        "    df.drop(columns=['id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver'], inplace=True)\n",
        "\n",
        "    def preprocess_country(text):\n",
        "        # 나라 이름으로 전처리\n",
        "        for country in list(country_list):\n",
        "            if country in text:\n",
        "                # print(country, text)\n",
        "                return country\n",
        "        return 'other'\n",
        "\n",
        "    # 'customer_country' 열에 대해 전처리 적용\n",
        "    df['customer_country'] = df['customer_country'].fillna('unknown')\n",
        "    df['customer_country'] = df['customer_country'].str.lower()\n",
        "    df['customer_country'] = df['customer_country'].apply(preprocess_country)\n",
        "\n",
        "    # customer_country.1 드롭\n",
        "    df.drop(columns=['customer_country.1'], inplace=True)\n",
        "\n",
        "    # 데이터를 문자열로 변환하는 함수\n",
        "    def convert_to_string(value):\n",
        "        return str(value) if value is not None else ''\n",
        "\n",
        "    def preprocess_inquiry(text):\n",
        "        # 문자열로 변환\n",
        "        text = convert_to_string(text)\n",
        "\n",
        "        # 소문자로 변환\n",
        "        text = text.lower()\n",
        "\n",
        "        # 특수 문자 제거\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        # 중복된 값 처리\n",
        "        if 'technical' in text and text != 'technical support':\n",
        "            return 'technical'\n",
        "        if 'quotation' in text:\n",
        "            return 'quotation'\n",
        "        if 'sales' in text:\n",
        "            return 'sales'\n",
        "        if 'other' in text or 'etc' in text:\n",
        "            return 'other'\n",
        "        for inquiry in ['customer suggestions', 'nan', 'technical support', 'partnership', 'distributorship', 'demo', 'services', 'product information', 'trainings']:\n",
        "            if inquiry in text:\n",
        "                return text\n",
        "        return 'others'\n",
        "\n",
        "    # 'inquiry_type' 열에 대해 전처리 적용\n",
        "    df['inquiry_type'] = df['inquiry_type'].apply(preprocess_inquiry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOT5Kb11SopN"
      },
      "outputs": [],
      "source": [
        "preprocessing(df_train)\n",
        "preprocessing(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3FGw2_ISp_V"
      },
      "outputs": [],
      "source": [
        "# 파생변수 생성 함수\n",
        "def generate_feature(df):\n",
        "    # bant_submit\n",
        "    df['bant_submit_count'] = df['bant_submit'].apply(lambda x: 1 if x == 0 else 0)\n",
        "\n",
        "    # com_reg_ver_win_rate\n",
        "    df['com_reg_count'] = df['com_reg_ver_win_rate'].apply(lambda x: 1 if x > 0.04 else 0)\n",
        "\n",
        "    # customer_idx\n",
        "    idx_count = df['customer_idx'].value_counts()\n",
        "    df['idx_count'] = df['customer_idx'].apply(lambda x: 1 if x in idx_count[idx_count>1].index else 0)\n",
        "\n",
        "    # lead_desc_length\n",
        "    df['lead_log'] = df['lead_desc_length'].apply(lambda x: np.log(x))\n",
        "    df['lead_count'] = df['lead_log'].apply(lambda x: 1 if x > 3.367296 else 0)\n",
        "    # 전처리 과정에서 일단 lead_desc_length를 제거하진 않겠습니다\n",
        "\n",
        "    # historical_existing_cnt\n",
        "    df['enterprise_count'] = 0\n",
        "    df.loc[(df['enterprise'] == 'Enterprise')&(df['historical_existing_cnt']!=0), 'enterprise_count'] = 1\n",
        "\n",
        "    # enterprise, SMB 둘 다 있는 회사명에 가중치\n",
        "    enterprise_2 = df.groupby('customer_idx')['enterprise'].nunique()\n",
        "    idx = enterprise_2[enterprise_2==2].index\n",
        "    df.loc[df['customer_idx'].isin(idx), 'enterprise_weight'] = 1\n",
        "    df.loc[~df['customer_idx'].isin(idx), 'enterprise_weight'] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cEqzqf8Sthi"
      },
      "outputs": [],
      "source": [
        "generate_feature(df_train)\n",
        "generate_feature(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "rDE00XXFSuoo",
        "outputId": "cf08ac97-d786-4e42-cf12-6bbcca8d9214"
      },
      "outputs": [],
      "source": [
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "410n1oGnSwS8",
        "outputId": "a9721021-7dc5-454a-e0a0-d9b7af4e48ab"
      },
      "outputs": [],
      "source": [
        "df_test.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0itQhtVqSxs3"
      },
      "outputs": [],
      "source": [
        "# 전처리 파일 저장\n",
        "df_train.to_csv(\"train_last.csv\", index=False)\n",
        "df_test.to_csv(\"submission_last.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehDgXE4yScTN"
      },
      "source": [
        "## catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_c-Eix40mub"
      },
      "outputs": [],
      "source": [
        "# 레이블 인코딩할 칼럼들\n",
        "cat_columns = [\n",
        "    \"customer_country\",\n",
        "    \"business_subarea\",\n",
        "    \"business_area\",\n",
        "    \"business_unit\",\n",
        "    \"customer_type\",\n",
        "    \"customer_idx\",\n",
        "    \"enterprise\",\n",
        "    \"customer_job\",\n",
        "    \"inquiry_type\",\n",
        "    \"product_category\",\n",
        "    \"product_subcategory\",\n",
        "    \"product_modelname\",\n",
        "    \"customer_position\",\n",
        "    \"response_corporate\",\n",
        "    \"expected_timeline\",\n",
        "    \"category\",\n",
        "    \"product_count\",\n",
        "    \"timeline_count\",\n",
        "    \"idit_all\",\n",
        "    \"lead_owner\",\n",
        "\n",
        "    \"com_reg_count\",\n",
        "    \"idx_count\",\n",
        "    \"lead_count\",\n",
        "    \"enterprise_count\",\n",
        "    \"enterprise_weight\"\n",
        "]\n",
        "\n",
        "def index_processing(context_df, train, test, column_name):\n",
        "    idx = {v:k for k,v in enumerate(context_df[column_name].unique())}\n",
        "    train[column_name] = train[column_name].map(idx)\n",
        "    test[column_name] = test[column_name].map(idx)\n",
        "    # train.loc[:, column_name] = train[column_name].map(idx)\n",
        "    # test.loc[:, column_name] = test[column_name].map(idx)\n",
        "    return idx\n",
        "\n",
        "def process_context_data(train_df, test_df):\n",
        "    context_df = pd.concat([train_df[cat_columns], test_df[cat_columns]]).reset_index(drop=True)\n",
        "    idx = {}\n",
        "    for col in cat_columns:\n",
        "        idx_name = index_processing(context_df, train_df, test_df, col)\n",
        "        idx[col+'2idx'] = idx_name\n",
        "    return idx, train_df, test_df\n",
        "\n",
        "def context_data_load():\n",
        "    ######################## DATA LOAD\n",
        "    train = pd.read_csv('train_last.csv', low_memory=False)\n",
        "    test = pd.read_csv('submission_last.csv')\n",
        "\n",
        "    idx, context_train, context_test = process_context_data(train, test)\n",
        "    field_dims = np.array([len(toidx) for toidx in idx], dtype=np.int32)\n",
        "\n",
        "    data = {\n",
        "            'train':context_train.fillna(0),\n",
        "            'test':context_test.fillna(0),\n",
        "            'field_dims':field_dims,\n",
        "            'cat_columns' : cat_columns,\n",
        "            }\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "def context_data_split(data):\n",
        "    # SMOTE를 사용하여 데이터 오버샘플링\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(data['train'].drop(['is_converted'], axis=1), data['train']['is_converted'])\n",
        "\n",
        "    # 샘플링된 데이터를 다시 훈련 데이터와 테스트 데이터로 분할\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X_resampled,\n",
        "                                                      y_resampled,\n",
        "                                                      test_size=0.2,\n",
        "                                                      random_state=42,\n",
        "                                                      stratify=y_resampled)\n",
        "\n",
        "    y_train = y_train.astype(np.int32) ; y_valid = y_valid.astype(np.int32)\n",
        "    data['X_train'], data['X_valid'], data['y_train'], data['y_valid'], data['X_resampled'], data['y_resampled'] = X_train, X_valid, y_train, y_valid, X_resampled, y_resampled\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca5urtBF0q3B"
      },
      "outputs": [],
      "source": [
        "data = context_data_load()\n",
        "data = context_data_split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8ZFQ7kj0sDd"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = data['X_train'], data['X_valid'], data['y_train'], data['y_valid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOK0tNzf1HEy"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.drop('bant_submit_count', axis=1)\n",
        "x_train = x_train.drop('ver_pro', axis=1)\n",
        "x_val = x_val.drop('ver_pro', axis=1)\n",
        "x_val = x_val.drop('bant_submit_count', axis=1)\n",
        "data['X_resampled'] = data['X_resampled'].drop('ver_pro', axis=1)\n",
        "data['X_resampled'] = data['X_resampled'].drop('bant_submit_count', axis=1)\n",
        "data['test']=data['test'].drop('ver_pro', axis=1)\n",
        "data['test']=data['test'].drop('bant_submit_count', axis=1)\n",
        "data['X_valid'] = data['X_valid'].drop('ver_pro', axis=1)\n",
        "data['X_valid']=data['X_valid'].drop('bant_submit_count', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNSjIrm-0uXe"
      },
      "outputs": [],
      "source": [
        "# bool-> 1,0\n",
        "y_train = y_train.astype(int)\n",
        "y_valid = y_val.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Oyyn-1_hTXz"
      },
      "outputs": [],
      "source": [
        "param = {\"random_state\":42,\n",
        "            \"objective\": \"Logloss\",\n",
        "            \"cat_features\" : data['cat_columns'],\n",
        "         'learning_rate': 0.06979873507394162, 'bagging_temperature': 49.5227392420259, 'n_estimators': 1309, 'max_depth': 15, 'random_strength': 26, 'l2_leaf_reg': 1.987904330777592e-05, 'min_child_samples': 34, 'max_bin': 356, 'od_type': 'IncToDec'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0bFBh5rhdGR"
      },
      "outputs": [],
      "source": [
        "model = cb.CatBoostClassifier(**param, devices = '0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB-QPytMhpex"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "            data['X_resampled'],\n",
        "            data['y_resampled'].astype(int),\n",
        "            eval_set=[(x_val, y_val)],\n",
        "            early_stopping_rounds = 50,\n",
        "            verbose=10\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lCv2_BF1PSu"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, y_pred=None):\n",
        "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
        "\n",
        "    print(\"오차행렬:\\n\", confusion)\n",
        "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
        "    print(\"정밀도: {:.4f}\".format(precision))\n",
        "    print(\"재현율: {:.4f}\".format(recall))\n",
        "    print(\"F1: {:.4f}\".format(F1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry4ZkupN1ZWs"
      },
      "outputs": [],
      "source": [
        "# 테스트 데이터로 예측\n",
        "pred_proba = model.predict_proba(data['X_valid'])[:,1]\n",
        "threshold = np.median(pred_proba)\n",
        "pred = pred_proba >= threshold\n",
        "get_clf_eval(data['y_valid'], pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B12KyK2AEeUZ"
      },
      "outputs": [],
      "source": [
        "print(threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx3RrUjm1bYw"
      },
      "outputs": [],
      "source": [
        "# 예측에 필요한 데이터 분리\n",
        "test_pred_proba = model.predict_proba(data['test'].drop([\"is_converted\", \"id\"], axis=1))[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8kn7zif1dqE"
      },
      "outputs": [],
      "source": [
        "threshold = np.median(test_pred_proba)\n",
        "test_pred = (test_pred_proba >= threshold).astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9HJCFLQ8_3"
      },
      "outputs": [],
      "source": [
        "sum(test_pred) # True로 예측된 개수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8FV3xFI2fOO"
      },
      "outputs": [],
      "source": [
        "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
        "df_sub = pd.read_csv(\"submission.csv\")\n",
        "df_sub[\"is_converted\"] = test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuAPuvIx2i0G"
      },
      "outputs": [],
      "source": [
        "# 제출 파일 저장\n",
        "df_sub.to_csv(\"submission_cat.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql6Ji3MhuG5D"
      },
      "source": [
        "## TabNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy2shFCYuOT0"
      },
      "outputs": [],
      "source": [
        "# categorical 변수\n",
        "label = ['customer_country', 'business_unit', 'customer_idx', 'customer_type',\n",
        "         'enterprise', 'customer_job', 'inquiry_type', 'product_category', 'product_subcategory', 'product_modelname',\n",
        "         'customer_position', 'response_corporate', 'expected_timeline',\n",
        "         'business_area', 'business_subarea', 'lead_owner', 'category', 'idit_all']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hoTS9elye0q"
      },
      "outputs": [],
      "source": [
        "# f1 score metric 지정\n",
        "class F1_Score(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = 'F1_score'\n",
        "        self._maximize = True\n",
        "\n",
        "    def __call__(self, y_true, y_score):\n",
        "        y_pred = np.argmax(y_score, axis = 1)\n",
        "        score = f1_score(y_true, y_pred, average = 'macro')\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAlAqyYbyi8b"
      },
      "outputs": [],
      "source": [
        "def preprocessing(df_train, df_test, label):\n",
        "    df_all = pd.concat([df_train, df_test.drop('id', axis = 1)] , ignore_index = True)\n",
        "\n",
        "    # 전처리\n",
        "    df_all['inquiry_type'] = df_all['inquiry_type'].fillna('nan')\n",
        "\n",
        "    # business area, subarea 모두 nan으로 채움\n",
        "    df_all['business_area'] = df_all['business_area'].fillna('nan')\n",
        "    df_all['business_subarea'] = df_all['business_subarea'].fillna('nan')\n",
        "\n",
        "    # ver_win_rate_x, ver_win_ratio_per_bu, com_reg_ver_win_rate 모두 null값 0으로 처리\n",
        "    df_all['ver_win_rate_x'] = df_all['ver_win_rate_x'].fillna(0)\n",
        "    df_all['ver_win_ratio_per_bu'] = df_all['ver_win_ratio_per_bu'].fillna(0)\n",
        "    df_all['com_reg_ver_win_rate'] = df_all['com_reg_ver_win_rate'].fillna(0)\n",
        "\n",
        "    # label encoding\n",
        "    for col in label:\n",
        "        le = LabelEncoder()\n",
        "        df_all[col] = le.fit_transform(df_all[col].values)\n",
        "\n",
        "    # train, test 다시 분리\n",
        "    df_train = df_all.iloc[: len(df_train)]\n",
        "    df_test = df_all.iloc[len(df_train):]\n",
        "\n",
        "    # target 인코딩\n",
        "    df_train['is_converted'] = df_train['is_converted'].apply(lambda x: 1 if x == True else 0)\n",
        "\n",
        "    return df_train, df_test, df_all\n",
        "\n",
        "# smote\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "def smote(method, df):\n",
        "    smt = SMOTE(random_state = 400)\n",
        "    smoteto = SMOTETomek(tomek = TomekLinks(sampling_strategy = 'majority'), random_state = 400)\n",
        "    bdsmt = BorderlineSMOTE(random_state = 400)\n",
        "\n",
        "    if method == 'smt':\n",
        "        trsx, trsy = smt.fit_resample(df.drop('is_converted', axis = 1), df['is_converted'])\n",
        "\n",
        "    elif method == 'smoteto':\n",
        "        trsx, trsy = smoteto.fit_resample(df.drop('is_converted', axis = 1), df['is_converted'])\n",
        "\n",
        "    elif method == 'bdsmt':\n",
        "        trsx, trsy = bdsmt.fit_resample(df.drop('is_converted', axis = 1), df['is_converted'])\n",
        "    else:\n",
        "        print('method error')\n",
        "\n",
        "    return trsx, trsy\n",
        "\n",
        "def before_train(smote_method, df, label):\n",
        "    # 오버샘플링\n",
        "    # smote: smt, smote+tomek: smoteto, borderline smote: bdsmt\n",
        "    trsx, trsy = smote(smote_method, df)\n",
        "\n",
        "    # cat_idxs, cat_dims 지정\n",
        "    use_label = [col for col in df.columns if col in label]\n",
        "\n",
        "    categorical_dim = {}\n",
        "    for col in use_label:\n",
        "        categorical_dim[col] = df_all[col].nunique()\n",
        "\n",
        "    cat_idxs = [trsx.columns.get_loc(col) for col in use_label]\n",
        "    cat_dims = [categorical_dim[f] for f in use_label]\n",
        "\n",
        "    return trsx, trsy, cat_idxs, cat_dims\n",
        "\n",
        "def result_vis(model, df):\n",
        "    # f1_score, loss\n",
        "    fig, ax = plt.subplots(1,2, figsize = (16,8))\n",
        "\n",
        "    ax[0].plot(model.history['val_0_F1_score'])\n",
        "    ax[0].set_title('f1_score')\n",
        "    ax[1].plot(model.history['loss'])\n",
        "    ax[1].set_title('loss')\n",
        "\n",
        "    # feature importances\n",
        "    feature_importances = model.feature_importances_\n",
        "    num_features = len(feature_importances)\n",
        "    plt.figure(figsize = (10,6))\n",
        "    plt.barh(range(num_features), feature_importances, align = 'center')\n",
        "    plt.yticks(np.arange(num_features), df.drop('is_converted', axis = 1).columns)\n",
        "    plt.xlabel('feature importance')\n",
        "    plt.title('tabnet feature importances')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07cmb9lgyjgx"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, y_pred=None):\n",
        "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
        "\n",
        "    print(\"오차행렬:\\n\", confusion)\n",
        "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
        "    print(\"정밀도: {:.4f}\".format(precision))\n",
        "    print(\"재현율: {:.4f}\".format(recall))\n",
        "    print(\"F1: {:.4f}\".format(F1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1DKtzHByl-1"
      },
      "outputs": [],
      "source": [
        "# 데이터 전처리\n",
        "df_train, df_test, df_all = preprocessing(df_train, df_test, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRiSmrftynW3"
      },
      "outputs": [],
      "source": [
        "# 상관관계 낮은 변수 제거\n",
        "train_04 = df_train[['customer_country', 'com_reg_ver_win_rate', 'enterprise',\n",
        "       'historical_existing_cnt', 'customer_job', 'customer_position',\n",
        "       'expected_timeline', 'ver_win_rate_x', 'business_subarea', 'lead_owner',\n",
        "       'is_converted', 'product_count', 'timeline_count', 'bant_submit_count',\n",
        "       'lead_count', 'enterprise_weight']]\n",
        "\n",
        "test_04 = df_test[['customer_country', 'com_reg_ver_win_rate', 'enterprise',\n",
        "       'historical_existing_cnt', 'customer_job', 'customer_position',\n",
        "       'expected_timeline', 'ver_win_rate_x', 'business_subarea', 'lead_owner',\n",
        "       'is_converted', 'product_count', 'timeline_count', 'bant_submit_count',\n",
        "       'lead_count', 'enterprise_weight']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPlUUWHly9j1"
      },
      "outputs": [],
      "source": [
        "# borderline smote 사용\n",
        "trsx, trsy, cat_idxs, cat_dims = before_train('bdsmt', df_train, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTtkYOIfzE-S"
      },
      "outputs": [],
      "source": [
        "trsx = trsx.values\n",
        "trsy = trsy.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq1iIyKWzMj9"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    trsx,\n",
        "    trsy,\n",
        "    stratify = trsy,\n",
        "    shuffle = True,\n",
        "    random_state = 400\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHBlHoA8zGMc"
      },
      "outputs": [],
      "source": [
        "tabnet_params = dict(n_d = 8, n_a = 8, n_steps = 1,\n",
        "                    cat_idxs = cat_idxs, cat_dims = cat_dims,\n",
        "                    gamma = 2.0, lambda_sparse = 2.057796554216087e-05,\n",
        "                    optimizer_fn = torch.optim.Adam,\n",
        "                    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
        "                    mask_type = 'entmax', n_shared = 2, n_independent = 5,\n",
        "                    cat_emb_dim = 9,\n",
        "                    seed = 0,\n",
        "                    scheduler_params = dict(mode = 'min',\n",
        "                                            patience = 5,\n",
        "                                            min_lr = 1e-5,\n",
        "                                            factor = 0.5),\n",
        "                    scheduler_fn = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                    verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSH6GXWYsnPR",
        "outputId": "0d38e277-9a28-4199-ba72-376f3b5442c1"
      },
      "outputs": [],
      "source": [
        "clf = TabNetClassifier(**tabnet_params)\n",
        "clf.fit(X_train = x_train, y_train = y_train,\n",
        "        eval_set = [(x_val, y_val)],\n",
        "        patience = 3, max_epochs = 52,\n",
        "        virtual_batch_size = 256, batch_size = 2048,\n",
        "        weights = 0,\n",
        "        num_workers = 0,\n",
        "        eval_metric = ['F1_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I789uV2zOr3"
      },
      "outputs": [],
      "source": [
        "# pr curve에서 가장 최적점(precision, recall 모두 높은 threshold) 찾는 함수\n",
        "# 참고용\n",
        "def find_optimal_threshold(y_true, y_scores):\n",
        "  precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
        "\n",
        "  f1_scores = 2 *(precision * recall) / (precision + recall)\n",
        "  optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
        "\n",
        "  return optimal_threshold\n",
        "\n",
        "y_scores = clf.predict_proba(x_val)[:,1]\n",
        "threshold = find_optimal_threshold(y_val, y_scores)\n",
        "threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0y8etVgs_Zn",
        "outputId": "558f718e-dbed-4f6c-8ba4-22ae7843040f"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(x_val)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG1XH7OGs_Zo",
        "outputId": "11d4f055-4827-42e4-8d8e-906ad867b8fa"
      },
      "outputs": [],
      "source": [
        "y_scores = clf.predict_proba(x_val)[:,1]\n",
        "threshold = find_optimal_threshold(y_val, y_scores)\n",
        "threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3juoa4wtC7D"
      },
      "outputs": [],
      "source": [
        "x_test = test_04.drop('is_converted', axis = 1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFj71hJ_s_Zo",
        "outputId": "22ba563f-2c78-4012-fcdf-2c19067009e7"
      },
      "outputs": [],
      "source": [
        "pred_proba = clf.predict_proba(x_test)[:,1]\n",
        "pred_proba_ex = (pred_proba>threshold).astype(int)\n",
        "compare(pred_proba_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_w--tkFs_Zo"
      },
      "outputs": [],
      "source": [
        "# x_test = df_test.drop('is_converted', axis = 1).values\n",
        "pred = clf.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NL_I0zzs_Zp",
        "outputId": "45f6f2ed-6ef5-4d12-9498-2e389916ae84"
      },
      "outputs": [],
      "source": [
        "compare(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H--Ym62HvOh7"
      },
      "outputs": [],
      "source": [
        "df_sub = pd.read_csv('submission (1).csv')\n",
        "df_sub['is_converted'] = pred_proba_ex # threshold 기준 데이터 분류\n",
        "df_sub['is_converted_proba'] = pred_proba\n",
        "df_sub.to_csv('submission_tabnet.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "anSPPaE6up1a",
        "outputId": "137f61d0-04c3-487e-da41-2650008ab4d2"
      },
      "outputs": [],
      "source": [
        "feature_importances = clf.feature_importances_\n",
        "num_features = len(feature_importances)\n",
        "plt.figure(figsize = (10,6))\n",
        "plt.barh(range(num_features), feature_importances, align = 'center')\n",
        "plt.yticks(np.arange(num_features), train_04.drop('is_converted', axis = 1).columns)\n",
        "plt.xlabel('feature importance')\n",
        "plt.title('tabnet feature importances')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHlXtHfgG38Y"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHBnHEGcG25F"
      },
      "outputs": [],
      "source": [
        "# DATA LOAD\n",
        "data = context_data_load()\n",
        "\n",
        "# Train/Valid Split\n",
        "data = context_data_split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "I45aaC_DG-cM",
        "outputId": "0c1c490a-93d7-4637-c532-2dc9ad16e1fb"
      },
      "outputs": [],
      "source": [
        "data['train'] # 학습용 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzyEwbczHAex"
      },
      "outputs": [],
      "source": [
        "X, y = data['X_resampled'], data['y_resampled']\n",
        "test = data['test'].drop([\"is_converted\", \"id\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVI0WWcqHTV2",
        "outputId": "01220fd8-9d59-4e9a-bbc4-9e3f35f3e1d0"
      },
      "outputs": [],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5N11hKWHVLN"
      },
      "outputs": [],
      "source": [
        "categorical_feature = data['cat_columns']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "046ZvREeHXQ4"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = data['X_train'], data['X_valid'], data['y_train'], data['y_valid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZFFBT0rHZde"
      },
      "outputs": [],
      "source": [
        "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature = categorical_feature, free_raw_data=False)\n",
        "val_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature = categorical_feature, free_raw_data=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "n5J18RPTHcdN",
        "outputId": "7ec3eca0-137b-4377-f53a-585aad69bc6b"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "      param = {\n",
        "          \"objective\": \"binary\",\n",
        "          \"metric\": \"binary_logloss\",\n",
        "          \"verbosity\": -1,\n",
        "          \"max_bin \": 510,\n",
        "          \"boosting_type\": 'gbdt',\n",
        "          'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
        "          \"n_estimators\":trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "          \"max_depth\":trial.suggest_int(\"max_depth\", 4, 20),\n",
        "          \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 100)\n",
        "          }\n",
        "\n",
        "      # LightGBM 모델 학습\n",
        "      lgb_model = lgb.train(param, train_data, valid_sets =[val_data],\n",
        "                            num_boost_round=10, categorical_feature = categorical_feature)\n",
        "      preds = lgb_model.predict(X_valid, num_iteration=lgb_model.best_iteration)\n",
        "      pred_labels = np.rint(preds)\n",
        "      F1 = f1_score(y_valid, pred_labels)\n",
        "      return F1\n",
        "\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name = 'lgbm_parameter_optuna',\n",
        "    direction = 'maximize',\n",
        "    sampler = sampler,\n",
        ")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "model = lgb.train(study.best_params, train_data, valid_sets =[val_data],\n",
        "                  num_boost_round=10, categorical_feature = categorical_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQFYCOpnHqj8"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, y_pred=None):\n",
        "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
        "\n",
        "    print(\"오차행렬:\\n\", confusion)\n",
        "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
        "    print(\"정밀도: {:.4f}\".format(precision))\n",
        "    print(\"재현율: {:.4f}\".format(recall))\n",
        "    print(\"F1: {:.4f}\".format(F1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb9ww6Q_HrgB"
      },
      "outputs": [],
      "source": [
        "# classifier\n",
        "pred = model.predict(X_valid)\n",
        "threshold = np.median(pred)\n",
        "pred = pred >= threshold\n",
        "get_clf_eval(y_valid, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqWUK7WnHuh5"
      },
      "outputs": [],
      "source": [
        "# 예측에 필요한 데이터 분리\n",
        "test_pred = model.predict(test)\n",
        "test_pred = test_pred >= threshold\n",
        "#classifier\n",
        "sum(test_pred) # True로 예측된 개수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA7KYtnVHwCt"
      },
      "outputs": [],
      "source": [
        "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
        "df_sub = pd.read_csv(\"submission.csv\")\n",
        "df_sub[\"is_converted\"] = test_pred\n",
        "df_sub[\"is_converted\"] = df_sub[\"is_converted\"].astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiLTrdXxHzKZ"
      },
      "outputs": [],
      "source": [
        "# 제출 파일 저장\n",
        "df_sub.to_csv(\"submission_lgbm.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ooytY_9L6XW"
      },
      "source": [
        "## randomforest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa2af1da"
      },
      "outputs": [],
      "source": [
        "# DATA LOAD\n",
        "data = context_data_load()\n",
        "\n",
        "# Train/Valid Split\n",
        "data = context_data_split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "7519ffbb",
        "outputId": "daeb45db-eb84-463e-f9a4-5a086497aafd"
      },
      "outputs": [],
      "source": [
        "data['train'] # 학습용 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7idZU-03WjWk"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = data['X_train'], data['X_valid'], data['y_train'], data['y_valid']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79ecfa9b"
      },
      "source": [
        "### 3. 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1TFc0AfTqii"
      },
      "outputs": [],
      "source": [
        "param = {\"random_state\":42,\n",
        "        'n_estimators': 105, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': True}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Qn6VzdThrp"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor(**param, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "_TtTpOE6ThLx",
        "outputId": "828c90bc-67bf-4601-bff1-46cd7256628e"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train.fillna(0), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPfGtuftzpQQ"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, y_pred=None):\n",
        "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
        "\n",
        "    print(\"오차행렬:\\n\", confusion)\n",
        "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
        "    print(\"정밀도: {:.4f}\".format(precision))\n",
        "    print(\"재현율: {:.4f}\".format(recall))\n",
        "    print(\"F1: {:.4f}\".format(F1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTpXNAJtzspg",
        "outputId": "6a74f667-9624-4352-b1e5-f375bbbfa5e5"
      },
      "outputs": [],
      "source": [
        "#Regressor\n",
        "pred = model.predict(x_val.fillna(0))\n",
        "threshold = np.median(pred)\n",
        "pred = pred >= threshold\n",
        "get_clf_eval(y_val, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDgD6f7M0B4-"
      },
      "outputs": [],
      "source": [
        "# 예측에 필요한 데이터 분리\n",
        "test_pred = model.predict(data['test'].drop([\"is_converted\", \"id\"], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNaellSv0BvZ",
        "outputId": "c175bf11-67f9-41be-d6fd-33d8663ecaee"
      },
      "outputs": [],
      "source": [
        "#Regressor\n",
        "test_pred = test_pred >= threshold\n",
        "sum(test_pred) # True로 예측된 개수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "anarhBMI3npC",
        "outputId": "e723e7d7-82f9-4d53-8b4f-4922cb61dcb8"
      },
      "outputs": [],
      "source": [
        "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
        "df_sub = pd.read_csv(\"submission.csv\")\n",
        "df_sub[\"is_converted\"] = test_pred\n",
        "df_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raapt-BI3-dS"
      },
      "outputs": [],
      "source": [
        "# 제출 파일 저장 (regressor)\n",
        "df_sub.to_csv(\"submission_rfr.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeP4qsfSXTuS"
      },
      "source": [
        "## 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCFD6BxGWXeU"
      },
      "outputs": [],
      "source": [
        "test_tab = pd.read_csv(\"submission_tabnet.csv\")\n",
        "test_cat = pd.read_csv(\"submission_cat.csv\")\n",
        "test_lgbm = pd.read_csv(\"submission_lgbm.csv\")\n",
        "test_rfr = pd.read_csv(\"submission_rfr.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP52G6qabgJt"
      },
      "outputs": [],
      "source": [
        "pred_cat = test_cat['is_converted'].apply(lambda x: 1.5*x)\n",
        "pred_lgbm = test_lgbm['is_converted'].apply(lambda x: 1 if x == True else 0)\n",
        "pred_tab = test_tab['is_converted_proba'].apply(lambda x: 1.3*x)\n",
        "pred_rfr = test_rfr['is_converted'].apply(lambda x: 1 if x == True else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "0Kqy1BSbWWgW",
        "outputId": "bb84cebb-801e-4bf6-f40a-9ce23f46aa94"
      },
      "outputs": [],
      "source": [
        "df_ensemble = pd.DataFrame()\n",
        "df_ensemble['cat'] = pred_cat\n",
        "df_ensemble['lgbm'] = pred_lgbm\n",
        "df_ensemble['tabnet'] = pred_tab\n",
        "df_ensemble['rfr'] = pred_rfr\n",
        "df_ensemble['sum'] = df_ensemble['cat'] + df_ensemble['lgbm'] + df_ensemble['tabnet'] + df_ensemble['rfr']\n",
        "df_ensemble['is_converted'] = df_ensemble['sum'].apply(lambda x: True if x > 2.525 else False)\n",
        "test_pred = df_ensemble['is_converted']\n",
        "print(sum(test_pred))\n",
        "df_ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "IcUeuS1ocxhd",
        "outputId": "e4cc8be2-8c20-4014-e535-0f8560c06001"
      },
      "outputs": [],
      "source": [
        "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
        "df_sub = pd.read_csv(\"submission.csv\")\n",
        "df_sub[\"is_converted\"] = test_pred\n",
        "df_sub[\"is_converted\"] = df_sub[\"is_converted\"].astype(bool)\n",
        "df_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgdyvy9keS7K"
      },
      "outputs": [],
      "source": [
        "# 제출 파일 저장 0.707742639040349\n",
        "df_sub.to_csv(\"submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CLYbW_xETXVe",
        "ehDgXE4yScTN",
        "Ql6Ji3MhuG5D",
        "dHlXtHfgG38Y",
        "4ooytY_9L6XW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
